{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = str(u\"C:\\\\Users\\\\Alison Link\\\\Documents\\\\INET4710\\\\FinalProjectData\\\\\")\n",
    "\n",
    "train_images = [\n",
    "    [data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409307_ne_15_1_20150927_20151221.tif', # just west of downtown St. Paul (by St. Paul campus)  \n",
    "    data_filepath + u'ground_truth_comparison_data\\\\comparison_clips\\\\comparison_clip_TRAIN.tif']\n",
    "]\n",
    "\n",
    "test_images = [\n",
    "    [data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409306_ne_15_1_20150930_20151221.tif', # downtown Minneapolis\n",
    "     data_filepath + u'ground_truth_comparison_data\\\\comparison_clips\\\\comparison_clip_TEST0.tif'],\n",
    "    [data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409307_nw_15_1_20150927_20151221.tif', # just east of downtown Minneapolis\n",
    "     data_filepath + u'ground_truth_comparison_data\\\\comparison_clips\\\\comparison_clip_TEST1.tif'],\n",
    "    [data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409308_nw_15_1_20150927_20151221.tif', # downtown St. Paul\n",
    "     data_filepath + u'ground_truth_comparison_data\\\\comparison_clips\\\\comparison_clip_TEST1.tif']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map which classes are NDVI positive and which are negative in the training and \n",
    "# \"ground truth\" data\n",
    "ndvi_dict = {\n",
    "    'target_ndvi_pos': [1, 2, 3],\n",
    "    'gt_ndvi_pos': [1, 6, 7, 8]\n",
    "    #'target_ndvi_neg': [4, 5, 6]\n",
    "    #'gt_ndvi_neg': [2, 3, 4, 12]\n",
    "}\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def calculate_ndvi_classification_performance(img_set, ndvi_dict):\n",
    "    ''' Does the model discern correctly between pixels that are NDVI + and NDVI - ? \n",
    "    Take an image set as an input (with the target image first, and the ground truth \n",
    "    comparison image second).  Compare where they match and where they don't. '''\n",
    "    \n",
    "    target_img = rasterio.open(img_set[0])\n",
    "    gt_img = rasterio.open(img_set[1])\n",
    "    \n",
    "    ndvi_classification_accuracy = np.empty(target_img.shape, dtype=rasterio.float32)\n",
    "    #print(target_img.shape)\n",
    "    #print(gt_img.shape)\n",
    "    #print(ndvi_classification_accuracy.shape)\n",
    "    #ndvi_classification_accuracy = np.where(((target_img in ndvi_dict['target_ndvi_pos']) and \n",
    "    #                                        (gt_img in ndvi_dict['gt_ndvi_pos'])), 1, 0)\n",
    "    \n",
    "    ndvi_classification_accuracy = np.isin(target_img, ndvi_dict['target_ndvi_pos'])\n",
    "    \n",
    "    return(ndvi_classification_accuracy)\n",
    "    \n",
    "    #fig, (ax1) = plt.subplots(1, 1, figsize=(21,7))\n",
    "    \n",
    "    #ax1.imshow(ndvi_classification_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ndvi_classification_performance(train_images[0], ndvi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map categories for comparison between train/test classification comparable values in the \n",
    "# \"ground truth\" data\n",
    "classification_compare_dict = {\n",
    "    0: [5, 9, 10, 11], # water features\n",
    "    1: [1, 8], # grass (and agriculture)\n",
    "    #2: # artificial turf\n",
    "    3: [6, 7], # trees\n",
    "    4: [2, 12], # dirt\n",
    "    5: [3, 4], # asphalt/buildings\n",
    "    6: [2, 12] # sand & light roofs\n",
    "}\n",
    "\n",
    "def calculate_classification_performance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
