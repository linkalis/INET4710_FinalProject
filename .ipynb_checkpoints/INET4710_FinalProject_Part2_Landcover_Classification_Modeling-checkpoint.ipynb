{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Landcover Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = str(u\"C:\\\\Users\\\\Alison Link\\\\Documents\\\\INET4710\\\\FinalProjectData\\\\\")\n",
    "\n",
    "train_images = [\n",
    "    data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409307_ne_15_1_20150927_20151221.tif' # just west of downtown St. Paul (by St. Paul campus)  \n",
    "]\n",
    "\n",
    "test_images = [\n",
    "    data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409306_ne_15_1_20150930_20151221.tif', # downtown Minneapolis\n",
    "    data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409307_nw_15_1_20150927_20151221.tif', # just east of downtown Minneapolis\n",
    "    data_filepath + u'naip\\\\2015\\\\twincities\\\\m_4409308_nw_15_1_20150927_20151221.tif', # downtown St. Paul\n",
    "    data_filepath + u'naip\\\\2015\\\\duluth\\\\m_4609215_se_15_1_20150922_20151221.tif', # Duluth north w/ some lake\n",
    "    data_filepath + u'naip\\\\2015\\\\duluth\\\\m_4609223_nw_15_1_20150922_20151221.tif', # Duluth w/ some lake\n",
    "    data_filepath + u'naip\\\\2015\\\\duluth\\\\m_4609216_sw_15_1_20150922_20151221.tif' # Duluth downtown w/ lots of lake  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data\n",
    "\n",
    "The first step in being able to run the NAIP imagery through a machine learning model is to coerce it into a format that is recognizable by scikit-learn and other standard libraries.  Generally, these kinds of modeling tools expect data to come formatted as a list.  Unfortunately, NAIP's standard structure looks like this:\n",
    "\n",
    "~5580 pixels (width) x ~7580 pixels (height) x 4 spectral bands (red, green, blue, near-infrared)\n",
    "\n",
    "The `make_img_long()` function below reshapes the data so it comes out like this:\n",
    "\n",
    "4 bands (columns) x ~4,200,000 pixels (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img_long(img_filepath, compute_ndvi=False):\n",
    "    start = time.time()\n",
    "    \n",
    "    dataset = rasterio.open(img_filepath)\n",
    "    img_metadata = dataset.meta.copy() # need to make a copy of this so we're not manipulating it in place\n",
    "    img_3darray = dataset.read()\n",
    "    \n",
    "    # Save height and width values so we can reconstruct the image later\n",
    "    height = img_3darray.shape[1] \n",
    "    width = img_3darray.shape[2]\n",
    "    \n",
    "    # Convert raster to list, then to dataframe\n",
    "    # See: https://gis.stackexchange.com/questions/32995/how-to-fully-load-a-raster-into-a-numpy-array\n",
    "    img_list = img_3darray.transpose(1, 2, 0).reshape(-1, 4).astype(float)\n",
    "    out_df = pd.DataFrame(data=img_list)\n",
    "    \n",
    "    if compute_ndvi:\n",
    "        print(\"Computing NDVI\")\n",
    "        \n",
    "        # NDVI = (IR band - red band) / (IR band + red band)\n",
    "        # See: https://www.earthdatascience.org/courses/earth-analytics-python/multispectral-remote-sensing-in-python/vegetation-indices-NDVI-in-python/\n",
    "        def ndvi_func(bands):\n",
    "            #print(bands)\n",
    "            #print(str(bands[0]) + \" : \" + str(bands[3]))\n",
    "            if (bands[1] + bands[4]) > 0:\n",
    "                ndvi = (bands[4] - bands[1]) / (bands[4] + bands[1])\n",
    "                #print(ndvi)\n",
    "                if ndvi > 0:\n",
    "                    return(ndvi)\n",
    "                else:\n",
    "                    return(ndvi)\n",
    "            else:\n",
    "                return(0)\n",
    "        \n",
    "        out_df['ndvi'] = [ndvi_func(row) for row in out_df.itertuples()]\n",
    "    \n",
    "    stop = time.time()\n",
    "    runtime = round(stop - start, 3)\n",
    "    print(\"Transformed image to dataframe in \" + str(runtime) + \" seconds.\")\n",
    "    return(out_df, img_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each NAIP image contains over 4,000,000 pixels, it takes approximately 1 minute to run this function.  Note that we are also computing the NDVI value for each pixel as we go along.  We are also saving the image metadata for later use, as this will come in handy when we need to coerce the image back into its original width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing NDVI\n",
      "Transformed image to dataframe in 63.469 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_img_df, train_img_metadata = make_img_long(train_images[0], compute_ndvi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df['ndvi'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NMF Models\n",
    "\n",
    "I initially started the modeling process with a very \"naive\" approach: I simply pumped the training image data through scikit-learn's NMF function, and told it to extract a 2-, 3-, 4-, 5-, or 6- class model with no additional discernment or segmentation between pixels being passed to the model.  The results were less than impressive:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[insert screenshot here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, a group of researchers at the EPA has an interesting finding when conducting a similar image classification task, also on NAIP imagery.  They made an important observation that seemed relevant to helping improve the model:\n",
    "\n",
    "> \"Shadows cast by vegetation and structures add significant noise to imagery at one meter resolution. Shadows typically appear at the edges of tall buildings and trees, and mottled within tree canopies, and are commonly misclassified as water or impervious surface. Using a binary step of classifying vegetation versus non-vegetation reduced these errors.\" (See: [Baynes, et al.](https://www.epa.gov/sites/production/files/2015-11/documents/baynes_esri_landcover_120313.pdf))\n",
    "\n",
    "With this in mind, I heavily adapted the model to the final version you see below.  The `fit_ndvi_segmented_nmf()` function proceeds as follows:\n",
    "\n",
    "1. It segments the image data into three classes based on their NDVI values: 1) pixels that likely represent water; 2) pixels with positive NDVI values; 3) pixels with negative NDVI values that are greater than the cutoff value used for water\n",
    "\n",
    "2. \n",
    "\n",
    "Because the training and test fit process share so many similar steps, the function below actually performs _both_ the training and test fits.  The user can select `mode = \"train\"` or `mode = \"test\"` to toggle between behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import joblib # for saving models\n",
    "\n",
    "def fit_ndvi_segmented_nmf(model_name, img_df_long, img_metadata, mode = \"train\",\n",
    "                           ndvi_water_cutoff = -0.35, ndvi_pos_components=2, ndvi_neg_components=2, \n",
    "                           save_to_file=False, filename= \"\"):\n",
    "    \n",
    "    # Get pixels that are obviously water\n",
    "    ndvi_water_pixels = img_df_long.loc[img_df_long['ndvi'] <= ndvi_water_cutoff]\n",
    "    \n",
    "    # Get pixels where NDVI value is > 0\n",
    "    ndvi_pos_pixels = img_df_long.loc[img_df_long['ndvi'] > 0]\n",
    "    \n",
    "    # Get pixels where NDVI value is < 0\n",
    "    ndvi_neg_pixels = img_df_long.loc[(img_df_long['ndvi'] > ndvi_water_cutoff) & (img_df_long['ndvi'] <= 0)]\n",
    "\n",
    "    if mode == \"train\":\n",
    "        # Fit NDVI positive model \n",
    "        start1 = time.time()\n",
    "        ndvi_pos_model = NMF(n_components=ndvi_pos_components, init='random', random_state=0)\n",
    "        ndvi_pos_model_W = ndvi_pos_model.fit_transform(ndvi_pos_pixels[[0, 1, 2, 3]]) # Pass only the 4-band pixel values to train one\n",
    "        ndvi_pos_model_H = ndvi_pos_model.components_\n",
    "        stop1 = time.time()\n",
    "        runtime1 = round(stop1 - start1, 3)\n",
    "        print(\"NDVI Positive Model completed in \" + str(runtime1) + \" seconds.\")\n",
    "        # Save the model for future use\n",
    "        joblib.dump(ndvi_pos_model, './models/{}_NMF_{}pos_classes.joblib'.format(model_name, ndvi_pos_components)) \n",
    "\n",
    "        # Fit NDVI negative model\n",
    "        start2 = time.time()\n",
    "        ndvi_neg_model = NMF(n_components=ndvi_neg_components, init='random', random_state=0)\n",
    "        ndvi_neg_model_W = ndvi_neg_model.fit_transform(ndvi_neg_pixels[[0, 1, 2, 3]])\n",
    "        ndvi_neg_model_H = ndvi_neg_model.components_\n",
    "        stop2 = time.time()\n",
    "        runtime2 = round(stop2 - start2, 3)\n",
    "        print(\"NDVI Negative Model completed in \" + str(runtime2) + \" seconds.\")\n",
    "        # Save the model for future use\n",
    "        joblib.dump(ndvi_neg_model, './models/{}_NMF_{}neg_classes.joblib'.format(model_name, ndvi_neg_components))\n",
    "    \n",
    "    if mode == \"test\":\n",
    "        print(\"Fitting positive/negative NDVI models to test data...\")\n",
    "        # Load models from file, then fit\n",
    "        start = time.time()\n",
    "        ndvi_pos_model = joblib.load('./models/{}_NMF_{}pos_classes.joblib'.format(model_name, ndvi_pos_components))\n",
    "        ndvi_pos_model_W = ndvi_pos_model.transform(ndvi_pos_pixels[[0, 1, 2, 3]])\n",
    "    \n",
    "        ndvi_neg_model = joblib.load('./models/{}_NMF_{}neg_classes.joblib'.format(model_name, ndvi_neg_components))\n",
    "        ndvi_neg_model_W = ndvi_neg_model.transform(ndvi_neg_pixels[[0, 1, 2, 3]])\n",
    "        \n",
    "        stop = time.time()\n",
    "        runtime = round(stop - start, 3)\n",
    "        print(\"Models fit to test data in \" + str(runtime) + \" seconds.\")\n",
    "    \n",
    "    # Classify using argmax to get the category with the highest weight for each pixel\n",
    "    ndvi_water_pixels['category'] = 0 # assign water pixels to category=0\n",
    "    ndvi_pos_pixels['category'] = np.argmax(ndvi_pos_model_W, axis=1) + 1 # offset category number by 1 to leave room for water class\n",
    "    ndvi_neg_pixels['category'] = np.argmax(ndvi_neg_model_W, axis=1) + 1 + ndvi_pos_components # make sure our category values don't overlap\n",
    "    \n",
    "    # Recombine dataframe by appending everything together, then sort on the index put pixels back in order\n",
    "    out_df = ndvi_water_pixels.append(ndvi_pos_pixels)\n",
    "    out_df = out_df.append(ndvi_neg_pixels).sort_index()\n",
    "    \n",
    "    # Take the categorized data and coerce into a numpy array that's in the shape of the original images\n",
    "    out_img = np.reshape(np.array(out_df['category']), (img_metadata['height'], img_metadata['width']))\n",
    "    \n",
    "    if save_to_file:\n",
    "        img_metadata.update({\n",
    "            'count': 1, # we now only have a single-band image containing integer classifications\n",
    "            'dtype': rasterio.uint8\n",
    "        })\n",
    "        \n",
    "        filename = './classified_images/{}_{}pos_{}neg_{}.tif'.format(model_name, ndvi_pos_components, ndvi_neg_components, filename)\n",
    "        # Save classified data to a GeoTIFF file\n",
    "        with rasterio.open(filename, \"w\", **img_metadata) as dest:\n",
    "            dest.write(out_img.astype(rasterio.uint8), 1)\n",
    "    else:\n",
    "        # Only return values if we haven't saved the results to a file; this takes up space in memory, \n",
    "        # so returning results in this way is not recommended for batch processing\n",
    "        return(out_df, out_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_ndvi_segmented_nmf('StPaulCampus', train_img_df, train_img_metadata, mode = \"train\",\n",
    "                       ndvi_neg_components = 3, ndvi_pos_components = 3, ndvi_water_cutoff = -0.3,\n",
    "                       save_to_file = True, filename = 'TRAIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to test images\n",
    "for i in range(len(test_images)):\n",
    "    print(\"Fitting image \" + str(i) + \"...\")\n",
    "    \n",
    "    # Convert the img to a list format\n",
    "    test_img_df, test_img_metadata = make_img_long(test_images[i], compute_ndvi=True) \n",
    "    \n",
    "    # Run the model and save the results to a file\n",
    "    filename_to_save = 'TEST' + str(i)\n",
    "    fit_ndvi_segmented_nmf('StPaulCampus', test_img_df, test_img_metadata, mode = \"test\",\n",
    "                           ndvi_neg_components = 5, ndvi_pos_components = 5, \n",
    "                           save_to_file = True, filename = filename_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training time\n",
    "\n",
    "| Nbr of classes | Train model     | Apply model to single test image |\n",
    "|----------------|-----------------| ---------------------------------|\n",
    "| 3 pos / 3 neg  | 5.5 min / 4min  | 3 min                            |\n",
    "| 5 pos / 5 neg  | 12 min / 9 min  | 7 min                            |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
